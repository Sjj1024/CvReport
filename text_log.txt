mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.
mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]
CUDA available: True
GPU 0,1: Tesla V100-PCIE-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.1+
------------------------------------------------------------

mmocr - INFO - Distributed training: False
mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
optimizer = dict(type='SGD', lr=0.001, momentum=0.99, weight_decay=0.0005)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[200, 400])
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=1)
max_seq_len = 30
dict_file = 'tests/data/chepai/label.txt'
label_convertor = dict(
    type='AttnConvertor',
    dict_file='tests/data/chepai/label.txt',
    with_unknown=True,
    max_seq_len=30)
model = dict(
    type='SARNet',
    backbone=dict(type='ResNet31OCR'),
    encoder=dict(
        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),
    decoder=dict(
        type='ParallelSARDecoder',
        enc_bi_rnn=False,
        dec_bi_rnn=False,
        dec_do_rnn=0,
        dec_gru=False,
        pred_dropout=0.1,
        d_k=512,
        pred_concat=True),
    loss=dict(type='SARLoss'),
    label_convertor=dict(
        type='AttnConvertor',
        dict_file='tests/data/chepai/label.txt',
        with_unknown=True,
        max_seq_len=30),
    max_seq_len=30)
img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=48,
        min_width=48,
        max_width=256,
        keep_aspect_ratio=True,
        width_downsample_ratio=0.25),
    dict(type='ToTensorOCR'),
    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio'
                ])
        ])
]
dataset_type = 'OCRDataset'
train_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
train_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt'
train = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
test_prefix = '/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs'
test_ann_file = '/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt'
test = dict(
    type='OCRDataset',
    img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
    ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
    loader=dict(
        type='HardDiskLoader',
        repeat=1,
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=False)
data = dict(
    samples_per_gpu=40,
    workers_per_gpu=2,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/train.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=48,
                min_width=48,
                max_width=256,
                keep_aspect_ratio=True,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,
                                                                0.5]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'resize_shape', 'text',
                    'valid_ratio'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='/home/ruanhaitao/mmocr-1.x/datasets/seals/imgs',
                ann_file='/home/ruanhaitao/mmocr-1.x/datasets/seals/val.txt',
                loader=dict(
                    type='HardDiskLoader',
                    repeat=1,
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=48,
                        min_width=48,
                        max_width=256,
                        keep_aspect_ratio=True,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'resize_shape',
                            'valid_ratio'
                        ])
                ])
        ]))
evaluation = dict(
    interval=1, save_best='0_word_acc_ignore_case_symbol', rule='greater')
work_dir = './work_dir/sealsar1023'
gpu_ids = [0]

mmocr - INFO - Set random seed to 1307072427, deterministic: False
mmocr - INFO - initialize ResNet31OCR with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
mmocr - INFO - initialize SAREncoder with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
Name of parameter - Initialization information

backbone.conv1_1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_1.bias - torch.Size([64]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_1.weight - torch.Size([64]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv1_2.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv1_2.bias - torch.Size([128]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1_2.weight - torch.Size([128]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn1_2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block2.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block2.0.downsample.1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block2.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv2.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.0.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.0.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block3.1.bn1.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block3.1.bn2.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv3.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv3.bias - torch.Size([256]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn3.weight - torch.Size([256]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.0.downsample.1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.3.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.3.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.3.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block4.4.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block4.4.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block4.4.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv4.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv4.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn4.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.0.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.0.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.1.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.1.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.block5.2.bn1.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.block5.2.bn2.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.block5.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

backbone.conv5.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.conv5.bias - torch.Size([512]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn5.weight - torch.Size([512]): 
UniformInit: a=0.0, b=1.0, bias=0 

backbone.bn5.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.rnn_encoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

encoder.linear.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv3x3_1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.conv1x1_2.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l0 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l0 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_ih_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.weight_hh_l1 - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_ih_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.rnn_decoder.bias_hh_l1 - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.embedding.weight - torch.Size([11380, 512]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.weight - torch.Size([11379, 1536]): 
The value is the same before and after calling `init_weights` of SARNet  

decoder.prediction.bias - torch.Size([11379]): 
The value is the same before and after calling `init_weights` of SARNet  
mmocr - INFO - Start running, host: ruanhaitao@zetyun, work_dir: /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023
mmocr - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
mmocr - INFO - workflow: [('train', 1)], max: 300 epochs
mmocr - INFO - Checkpoints will be saved to /home/ruanhaitao/MyProject/mmocr-main/work_dir/sealsar1023 by HardDiskBackend.